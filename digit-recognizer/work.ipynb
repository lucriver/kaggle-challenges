{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e231cae6-8bb5-4b57-9ce5-60968972e7bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HSA_OVERRIDE_GFX_VERSION'] = '10.3.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2269d6e6-c342-4409-b63d-de139279d68d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import gen_even_slices\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd0b9cf-4d52-438f-a661-873357bcc40b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = './data/digit-recognizer/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc13ed-0974-4bec-8f44-d42fc3ee2e9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3155f6-8db0-43e0-9e29-14d37352fc2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0aee4c-ebe7-4fc2-beea-3c086c2555b0",
   "metadata": {},
   "source": [
    "#### Separate images from labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde20a9c-ac30-45b1-afe1-5e4e53ddf4df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=['label'])\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f145b482-1214-4d66-aaaa-be04c05c99d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('labels:', y.unique())\n",
    "print('labels:', y.unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd4a545-58de-4916-8fcd-2198ea5353ab",
   "metadata": {},
   "source": [
    "### See an example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13dcdd9-d924-4292-abeb-256d38a48bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = X.sample()\n",
    "image = sample.values.reshape((28,28))\n",
    "idx = sample.index\n",
    "print('digit:',y.iloc[idx].values.squeeze())\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f1fe7d-adc3-49cf-af6f-fa2de5c6c9ca",
   "metadata": {},
   "source": [
    "### Work with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd81b9-dc60-4c9e-97d3-94304ccc3537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "display(torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de61cb0e-ede0-4fcf-9d77-dc96920d018b",
   "metadata": {},
   "source": [
    "### Reshape images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a0ccf-b1b2-4dd5-883b-82e2d1795246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = X.values\n",
    "labels = y.values\n",
    "\n",
    "images = images.reshape(-1, 1, 28, 28)\n",
    "labels = labels.reshape(-1, 1)\n",
    "\n",
    "images = torch.tensor(images, dtype=torch.float32, device=device)\n",
    "labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "\n",
    "print(f\"images: {images.shape}\")\n",
    "print(f\"labels: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485f6326-c4de-4beb-9e9e-8c9179b3673e",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network\n",
    "Before using some out-of-the-box classifier, lets try defining our own neural network using pytorch\n",
    "\n",
    "#### Model architecture: Convolutional neural network\n",
    "- Convolutional layers\n",
    "- Max pooling layers\n",
    "- linear layers w/ ReLU activation function\n",
    "- apply softmax to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec1dfd6-b0b7-44d9-8cd2-5bf3712c62de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3,3))\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        self.fc1 = nn.Linear(800, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.leaky_relu(self.conv1(x)))\n",
    "        x = self.pool(F.leaky_relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        x = self.forward(x)\n",
    "        y = torch.argmax(x, -1)\n",
    "        return y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599bdee3-6d54-4932-82f3-e2866081327e",
   "metadata": {},
   "source": [
    "## Training code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1cdeb6-d183-4d3b-a8c0-6eedbac0f60f",
   "metadata": {},
   "source": [
    "### Tune Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15608a17-4e82-47c3-a579-6c8699f14d9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.0001\n",
    "epochs = 18\n",
    "batch_size = 256\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "# perform CV for 5 folds\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(images)):\n",
    "    \n",
    "    # define train data for the fold\n",
    "    x_train, y_train = images[train_index], labels[train_index]\n",
    "    \n",
    "    # define test/validation data for the fold\n",
    "    x_test, y_test = images[test_index], labels[test_index]\n",
    "    \n",
    "    # define the model\n",
    "    model = NeuralNet().to(device)  \n",
    "    \n",
    "    # define the optimizer\n",
    "    optimizer = torch.optim.Adam(lr=learning_rate, params=model.parameters())\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    accuracies = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        slices = gen_even_slices(x_train.shape[0],x_train.shape[0]//batch_size)\n",
    "        for _, slice_ in enumerate(list(slices)):\n",
    "            x_batch = x_train[slice_.start:slice_.stop]\n",
    "            y_batch = y_train[slice_.start:slice_.stop]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(x_batch)\n",
    "                        \n",
    "            loss = loss_fn(output,y_batch.long().squeeze())\n",
    "            loss.backward()\n",
    "                        \n",
    "            optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_output = model(x_test)\n",
    "            val_loss = loss_fn(val_output, y_test.long().squeeze())\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "    # Plot the training and validation losses for the current fold\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot([i for i in range(len(train_losses))], train_losses, label='Training Loss')\n",
    "    plt.plot([i for i in range(len(val_losses))], val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training and Validation Loss - Fold {fold + 1}')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_test.cpu(),preds.cpu())\n",
    "        accuracies.append(accuracy)\n",
    "        print(f\"fold {fold + 1} accuracy: {accuracy}\")\n",
    "    \n",
    "print(f\"Mean accuracy: {np.mean(accuracies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843989b8-cb6a-4a4b-95a2-39c22d1f418c",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "03ad2501-0a47-4b8c-a66e-d7759c875085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09142445027828217\n",
      "0.061685554683208466\n",
      "0.05406118184328079\n",
      "0.03545704856514931\n",
      "0.030208753421902657\n",
      "0.014063914306461811\n",
      "0.022435840219259262\n",
      "0.024667326360940933\n",
      "0.004578050691634417\n",
      "0.0030519335996359587\n",
      "0.0029976926743984222\n",
      "0.006983173079788685\n",
      "0.002945544198155403\n",
      "0.0014546489110216498\n",
      "0.0013710251078009605\n",
      "0.001217078068293631\n",
      "0.000824407150503248\n",
      "0.0004694343078881502\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "epochs = 18\n",
    "batch_size = 256\n",
    "\n",
    "# define the model\n",
    "model = NeuralNet().to(device)  \n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(lr=learning_rate, params=model.parameters())\n",
    "\n",
    "# loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# prepare the data\n",
    "X, y = images, labels\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    slices = gen_even_slices(X.shape[0],X.shape[0]//batch_size)\n",
    "    for _, slice_ in enumerate(list(slices)):\n",
    "        \n",
    "        # prepare batches\n",
    "        x_batch = X[slice_.start:slice_.stop]\n",
    "        y_batch = y[slice_.start:slice_.stop]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model.forward(x_batch)\n",
    "\n",
    "        loss = loss_fn(output,y_batch.long().squeeze())\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    print(loss.item())\n",
    "                \n",
    "model.eval()\n",
    "torch.save(model.state_dict(), './data/weights.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033baf5e-749a-4b5a-bf8b-38054e8ccb93",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "f4362630-b7c0-4ab7-80c0-eae4001932be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./data/digit-recognizer/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "b25ecb8f-5f8e-49d1-85c1-94e1e2e4ca04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 1, 28, 28)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = df_test.values\n",
    "test_images = test_images.reshape(-1, 1, 28, 28)\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "1ad544b5-115a-4fd6-8dcf-42cd20dadb48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = torch.tensor(test_images, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "3aa42415-41c5-4474-b185-65fde5dc202b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28000])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model.predict(X_test)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "59c4c7f6-9856-4bfe-8ab9-bf81aff019cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      9\n",
       "4        5      3"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.DataFrame({'ImageId': [i+1 for i in range(len(y))], 'Label': y.cpu()})\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "bda76a01-32dc-4cd2-b11d-991637d1d636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('./data/my_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
